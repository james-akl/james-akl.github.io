<!doctype html><html lang=en><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Distribution anti-patterns ~ James Akl</title><link rel=canonical href=https://jamesakl.com/posts/distribution-antipatterns/><link rel=icon href=/favicon.ico sizes=any><link rel=icon href=/favicon.svg type=image/svg+xml><meta name=description content="Two common distribution problems emerge in robotics systems: distributing computation and distributing communication.
ROS 2 (robotics middleware built on DDS …"><meta name=author content="James Akl"><meta name=robots content="index, follow"><meta property="og:type" content="article"><meta property="og:url" content="https://jamesakl.com/posts/distribution-antipatterns/"><meta property="og:title" content="Distribution anti-patterns | James Akl"><meta property="og:description" content="Two common distribution problems emerge in robotics systems: distributing computation and distributing communication.
ROS 2 (robotics middleware built on DDS …"><meta property="og:site_name" content="James Akl"><meta property="og:locale" content="en_US"><meta property="article:published_time" content="2025-09-27T00:00:00Z"><meta property="article:modified_time" content="2025-09-27T00:00:00Z"><meta property="article:author" content="James Akl"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Distribution anti-patterns","description":"Two common distribution problems emerge in robotics systems: distributing computation and distributing communication.\nROS 2 (robotics middleware built on DDS …","url":"https:\/\/jamesakl.com\/posts\/distribution-antipatterns\/","datePublished":"2025-09-27T00:00:00Z","dateModified":"2025-09-27T00:00:00Z","author":{"@type":"Person","name":"James Akl","url":"https:\/\/jamesakl.com"},"publisher":{"@type":"Person","name":"James Akl","url":"https:\/\/jamesakl.com"}}</script><link rel=alternate type=application/rss+xml title="James Akl" href=https://jamesakl.com/index.xml><link rel=sitemap type=application/xml title=Sitemap href=https://jamesakl.com/sitemap.xml><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@300;400;500;600&family=Roboto+Mono:wght@400;500;600;700&display=swap" rel=stylesheet><style>:root{--primary-font:'Source Code Pro', sans-serif;--secondary-font:'Roboto Mono', monospace}[style*="var(--secondary-font)"],.mono{font-feature-settings:"kern" 1,"liga" 0,"calt" 1;letter-spacing:0}body{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}@media(-webkit-min-device-pixel-ratio:2),(min-resolution:192dpi){body{-webkit-font-smoothing:antialiased}}</style><style>:root{--bg-primary:#0d0d0d;--bg-secondary:#1a1a1a;--bg-tertiary:#242424;--text-primary:#e6e6e6;--text-secondary:#b0b0b0;--text-muted:#707070;--accent-primary:#60a5fa;--accent-secondary:#86efac;--accent-tertiary:#fbbf24;--border-subtle:#2a2a2a;--border-focus:#3f3f3f;--shadow:rgba(0, 0, 0, 0.3)}body{font-family:var(--primary-font);font-size:.9375rem;line-height:1.75;font-weight:400;text-rendering:geometricPrecision;-webkit-font-smoothing:subpixel-antialiased;-moz-osx-font-smoothing:auto;font-feature-settings:"kern" 1,"liga" 0,"calt" 1;padding:0;margin:0;background:var(--bg-primary);color:var(--text-primary);min-height:100vh;overflow-x:hidden;overflow-y:scroll}.site-container{max-width:75ch;margin:0 auto;padding:2rem 1.5rem;min-height:100vh;display:flex;flex-direction:column;box-sizing:border-box}.content{flex:1}h1,h2,h3,h4,h5,h6{font-family:var(--secondary-font);line-height:1.2;font-weight:600;letter-spacing:-.015em}h1{font-size:2rem;margin:0 0 .75rem;color:var(--text-primary);font-weight:700}h2{font-size:1.5rem;color:var(--text-primary);margin:3rem 0 1rem;padding-top:1.5rem;border-top:1px solid var(--border-subtle);font-weight:700}h2:first-of-type{border-top:none;padding-top:0;margin-top:2rem}h3{font-size:1.2rem;margin:2.5rem 0 1rem;font-weight:600;color:var(--text-primary)}h4{font-size:1rem;color:var(--accent-secondary);font-weight:600;margin:2rem 0 .75rem}p{margin:1rem 0;color:var(--text-primary)}strong{color:var(--accent-secondary);font-weight:600}em{font-style:italic}::selection{background:var(--accent-primary);color:var(--bg-primary)}::-webkit-scrollbar{width:8px}::-webkit-scrollbar-track{background:var(--bg-primary)}::-webkit-scrollbar-thumb{background:var(--border-focus);border-radius:4px}::-webkit-scrollbar-thumb:hover{background:var(--text-muted)}a{color:var(--accent-primary);text-decoration:none;transition:all .2s ease;border-radius:2px}a:hover{color:#8bb8e8}a:focus{outline:2px solid var(--accent-primary);outline-offset:2px}.site-header{display:flex;justify-content:space-between;align-items:center;padding:1rem 0 1.5rem;border-bottom:1px solid var(--border-subtle);margin-bottom:1.5rem}.site-title{font-family:var(--secondary-font);font-size:1rem;font-weight:400;color:var(--text-primary);text-decoration:none}.site-title:hover{color:var(--accent-primary)}.site-nav{display:flex;flex-wrap:wrap;gap:.25rem .75rem;align-items:center}.nav-link{font-family:var(--secondary-font);font-size:1rem;color:var(--text-primary);text-decoration:none;transition:color .2s ease}.nav-link:hover{opacity:1;color:var(--accent-primary)}.nav-icon{opacity:.7;transition:all .2s ease}.nav-icon:hover{opacity:1;transform:translateY(-1px)}.nav-icon svg{fill:var(--accent-secondary);transition:fill .2s ease}.sr-only{position:absolute;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0,0,0,0);border:0}.nav-icon:hover svg{fill:#a0f5bf}.content-section{margin:1.5rem 0}hr{border:none;height:1px;background:linear-gradient(to right,transparent,var(--border-subtle),transparent);margin:2rem 0}strong{color:var(--accent-secondary);font-weight:500}.section-table{display:grid;grid-template-columns:4rem 1fr auto;gap:.25rem 1rem;margin-top:1.5rem;align-items:baseline}.section-label{font-family:var(--secondary-font);font-size:.7rem;font-weight:400;color:var(--text-muted);text-transform:uppercase;letter-spacing:.04em;text-align:right}.section-title{font-family:var(--secondary-font);font-size:1rem;color:var(--text-primary);text-decoration:none}.section-title:hover{color:var(--accent-primary)}.section-meta{font-family:var(--secondary-font);font-size:.9rem;color:var(--text-muted);text-align:right}.section-about{grid-column:span 2;font-size:1rem;color:var(--text-secondary);line-height:1.6;text-align:justify;hyphens:auto;-webkit-hyphens:auto}.section-about p{margin:0}.section-spacer{grid-column:span 3;height:.75rem}@media(max-width:500px){.section-table{display:grid;grid-template-columns:1fr auto;gap:.25rem .75rem}.section-label{grid-column:span 2;text-align:left;margin-top:1rem}.section-label:first-child{margin-top:0}.section-label:empty{display:none}.section-about{grid-column:span 2}.section-spacer{grid-column:span 2;height:.5rem}}.project-list{font-family:var(--secondary-font)}.project-item{display:flex;justify-content:space-between;align-items:center;padding:.25rem 0;line-height:1.4}.project-link{color:var(--text-primary);text-decoration:none}.project-link:hover{color:var(--accent-primary)}.project-desc{color:var(--text-muted);font-size:.9rem}.post-list{margin:0;font-family:var(--secondary-font)}.post-item{display:flex;justify-content:space-between;align-items:center;padding:.25rem 0;line-height:1.4;gap:1rem}.post-meta{display:flex;align-items:center;gap:1rem;white-space:nowrap}.post-desc{color:var(--text-muted);font-size:.9rem}.post-date{color:var(--text-muted);font-size:.9rem}.post-line{display:flex;justify-content:space-between;align-items:center;padding:.25rem 0;line-height:1.4}.post-line:hover{background-color:rgba(255,255,255,5%);margin:0 -.5rem;padding-left:.5rem;padding-right:.5rem}.post-link{color:var(--text-primary);text-decoration:none;flex:1;margin-right:1rem}.post-link:hover{color:var(--accent-primary)}.post-date{color:var(--text-muted);font-size:.9rem;white-space:nowrap}.post-excerpt{margin:.75rem 0 0;color:var(--text-secondary);line-height:1.5}.read-more{color:var(--accent-primary);font-size:.85rem;margin-top:.5rem;display:inline-block;line-height:1.5;font-weight:400}.read-more:hover{color:var(--accent-secondary)}.post-header{margin-bottom:1.5rem}.post-navigation{display:flex;justify-content:space-between;margin:2rem 0 1rem;padding:1rem 0;border-top:1px solid var(--border-subtle);font-size:.95rem}.post-nav-prev,.post-nav-next{flex:1}.post-nav-next{text-align:right}.post-nav-label{color:var(--text-muted);font-size:.85rem;display:block;margin-bottom:.25rem}.post-nav-title{color:var(--accent-primary);font-weight:500}.post-footer{margin-top:auto;margin-bottom:1rem;padding-top:1rem;border-top:1px solid var(--border-subtle);font-size:.7rem;color:var(--text-muted);line-height:1.3}.post-footer .post-meta{justify-content:center;text-align:center;margin:0;white-space:normal}pre{background:var(--bg-secondary);border-left:3px solid var(--border-focus);border-radius:0;padding:1.25rem 1.5rem;margin:1.75rem 0;overflow-x:auto;font-family:var(--secondary-font);font-size:.875rem;line-height:1.6;font-weight:400;color:var(--text-primary);box-shadow:0 1px 3px var(--shadow)}code{font-family:var(--secondary-font);font-size:.875em;font-weight:500;background:var(--bg-secondary);color:var(--text-primary);padding:.2em .5em;margin:0;border-radius:2px;border:1px solid var(--border-subtle)}pre code{background:0 0;border:none;padding:0;margin:0;font-size:inherit;font-weight:400;color:inherit;white-space:pre}.mermaid{display:flex;justify-content:center;margin:2rem 0}.mermaid svg{max-height:500px}.mermaid .node rect{ry:3!important;rx:3!important}blockquote{margin:2rem 0;padding:1rem 1.5rem;border-left:4px solid var(--accent-secondary);background:var(--bg-secondary);font-style:italic;color:var(--text-secondary);box-shadow:0 1px 2px var(--shadow)}table{width:100%;border-collapse:collapse;margin:2rem 0;font-size:.875rem;line-height:1.5;display:table;table-layout:auto;background:var(--bg-secondary);box-shadow:0 1px 3px var(--shadow)}.content table{display:block;overflow-x:auto;-webkit-overflow-scrolling:touch}.content table table{display:table}thead{border-bottom:2px solid var(--border-focus)}th{text-align:left;padding:.75rem 1rem;font-weight:600;color:var(--accent-secondary);background:var(--bg-tertiary);white-space:nowrap;font-size:.875rem}td{padding:.65rem 1rem;border-bottom:1px solid var(--border-subtle);color:var(--text-primary);vertical-align:top}td code{font-size:.85em;padding:.15em .4em}tbody tr:hover{background:var(--bg-tertiary);transition:background .2s ease}ul,ol{margin:1.25rem 0;padding-left:2rem;line-height:1.7}li{margin:.5rem 0;color:var(--text-primary)}li>ul,li>ol{margin:.6rem 0}li::marker{color:var(--accent-secondary)}sub,sup{font-size:.75em;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}@media(max-width:640px){.site-container{padding:1.5rem 1rem}.site-header{padding:1rem 0 1.25rem}h1{font-size:1.8rem}h2{font-size:1.5rem}h3{font-size:1.2rem}.post-navigation{flex-direction:column;gap:1rem}.post-nav-next{text-align:left}.post-footer .post-meta{flex-direction:column;gap:.5rem;line-height:1.3}pre{padding:.85rem;font-size:.82rem;margin:1rem -.5rem;border-radius:0}code{font-size:.86em}table{font-size:.82rem}th,td{padding:.5rem .6rem}}</style><div class=site-container><header class=site-header><a class=site-title title=Home href=/>James Akl</a><nav class=site-nav><a class=nav-link href=mailto:james-akl@outlook.com>Email</a>
<a class=nav-link href=https://www.linkedin.com/in/james-akl/>LinkedIn</a>
<a class=nav-link href="https://scholar.google.com/citations?user=6gPp9TMAAAAJ">Scholar</a></nav></header><main class=content><article><header class=post-header><h1>Distribution anti-patterns</h1></header><div class=post-content><p>Two common distribution problems emerge in robotics systems: distributing <strong>computation</strong> and distributing <strong>communication</strong>.<p>ROS 2 <span style=color:#a9a9a9>(robotics middleware built on DDS for message passing and more)</span> is purpose-built for the communication problem — coordinating messages between robots, drivers, and software components across network boundaries. It is sometimes applied to the computation problem — parallelizing work inside a single system or process.<p>In prototyping, this approach can accelerate development. In more mature deployments, however, it can produce architectures where too many processing steps exist as separate nodes. This introduces serialization, network overhead, duplicated runtimes, and additional process management, where lighter concurrency primitives would suffice.<p>The core observation: <strong>the system&rsquo;s communication topology and the computation graph do not need to be identical.</strong> They can often be designed independently, reducing coupling to points where cross-process or cross-machine communication is genuinely required.<h2 id=the-two-problems>The two problems</h2><p>Understanding this anti-pattern requires distinguishing between two distinct distribution challenges:<p><strong>Distributed communication.</strong> Moving messages between processes, machines, or robots. ROS topics, services, and actions are designed for this; alternatives include ZeroMQ, RabbitMQ, Redis pub/sub, Kafka, or direct DDS for high-throughput or non-robotics applications.<p><strong>Distributed computation.</strong> Splitting work across cores, devices, or machines. This is handled by threading, multiprocessing, native accelerators (GPU, TPU, …), or distributed frameworks (Ray, Dask, Celery, …).<p>Note that “distributed” is usually reserved for work spread across multiple machines, while threads and processes on a single machine are described as parallelism or concurrency; here we discuss them together because the engineering trade-offs often overlap.<p>Most systems involve both: communication delivers results across boundaries, while computation accelerates processing within those boundaries. The issues can arise when tools designed for one problem are applied to the other.<h2 id=when-ros-becomes-the-default>When ROS becomes the default</h2><p>Faced with a parallel processing task, it is possible to implement each stage as a ROS node with appropriate communication primitives between them:<pre tabindex=0><code>/sensor_input → /preprocess → /algorithm → /post_process → /output
</code></pre><p>Costs of this pattern include:<ul><li>Serialization/deserialization and usually copies at each hop<li>Adaptation overhead and glue code for message types<li>Latency even for local operations (IPC ≠ direct call)<li>Duplicated memory/runtime across multiple processes, even when threads could suffice<li>Complexity in debugging and lifecycle management</ul><p>This illustrates using inter-system communication tools for intra-system computation. ROS 2 mitigations (composable nodes and intra-process transport) reduce per-hop overhead if nodes are colocated and the ROS execution model is followed, but this also admits the consideration of whether the processing work should be done via ROS.<h2 id=computation-tools>Computation tools</h2><p>Given this distinction, different tools address different aspects of the computation problem. Each offers specific trade-offs in concurrency, isolation, and performance:<h3 id=asyncio--cooperative-io>AsyncIO — cooperative I/O</h3><p>Useful for network or file I/O and coordinating multiple streams when callbacks are cooperative. Low scheduler overhead and avoids IPC when used within a single process. Less suitable for CPU-bound Python computation.<h3 id=threading--blocking-io-and-native-libraries>Threading — blocking I/O and native libraries</h3><p>Threads enable shared memory access while handling blocking I/O or delegating to native libraries that release the Python GIL. Practical for I/O-heavy tasks and interfacing with C/C++ extensions.<h3 id=multiprocessing--parallelism-and-isolation>Multiprocessing — parallelism and isolation</h3><p>Provides true parallelism for CPU-bound Python code. Offers process-level fault isolation and independent memory spaces.<h3 id=gpu-acceleration--high-throughput-local-compute-backend>GPU acceleration — high-throughput, local compute backend</h3><p>GPUs accelerate dense, data-parallel kernels such as matrix operations, convolutions, and large point-cloud filters. Practical considerations:<ul><li><strong>Batching and kernel aggregation:</strong> Minimize tiny host↔device transfers or kernel launches by combining operations or batching inputs.<li><strong>CUDA streams:</strong> Overlap computation and data transfer to improve device utilization. Input for batch <em>n+1</em> can transfer while batch <em>n</em> executes.<li><strong>Multi-GPU scaling:</strong> When a single GPU is insufficient, workloads can be partitioned across multiple GPUs (<em>e.g.</em>, <code>DistributedDataParallel</code> in <code>torch</code>), or across nodes using distributed frameworks like Ray.<li><strong>Shared memory / zero-copy:</strong> Large intermediate results exchanged with CPU processes or other GPUs benefit from shared memory (<code>multiprocessing.shared_memory</code>, CUDA pinned memory, or zero-copy DDS) to avoid repeated serialization.<li>The broader CUDA ecosystem also includes Unified Memory for simplifying host/device transfers, and NCCL for efficient multi-GPU communication.</ul><p>Illustrative pattern:<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>infer</span>(batch, device<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;cuda&#34;</span>):
    x <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(batch, device<span style=color:#f92672>=</span>device, copy<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
    <span style=color:#66d9ef>with</span> torch<span style=color:#f92672>.</span>no_grad():
        y <span style=color:#f92672>=</span> model(x)
    <span style=color:#66d9ef>return</span> y<span style=color:#f92672>.</span>cpu()<span style=color:#f92672>.</span>numpy()
</code></pre></div><p>Core points:<ul><li>Host↔device transfer latency and (de)serialization can dominate unless batching and stream concurrency are used.<li>Multi-GPU or distributed workloads require careful synchronization and memory management.<li>GPU computation often integrates with ROS or other frameworks at defined boundaries; maintaining computation in-process with clear interfaces simplifies coordination.</ul><h3 id=ray--dask--cluster-scale-computation>Ray / Dask — cluster-scale computation</h3><p>Used for multi-node scaling, distributed scheduling, and resilient execution. Appropriate when workloads exceed a single machine or require advanced scheduling/fault tolerance.<h3 id=ros--system-integration-and-cross-language-wiring>ROS — system integration and cross-language wiring</h3><p>ROS is most appropriate for hardware abstraction, driver stacks, multi-robot coordination, and interoperable message formats. Internal computation stages benefit from other concurrency primitives unless process isolation or robotics-specific tools are required.<h2 id=selection-criteria>Selection criteria</h2><p>These tools address different computational contexts:<ul><li><strong>ROS:</strong> integration surfaces, drivers, cross-process messaging<li><strong>AsyncIO:</strong> I/O-heavy pipelines inside a process<li><strong>Threading:</strong> blocking I/O or native libraries that release the GIL<li><strong>Multiprocessing:</strong> CPU-bound Python, isolation, multi-core scaling<li><strong>GPU:</strong> dense kernels, batched inference, heavy ops (minimize host↔device transfers)<li><strong>Ray/Dask:</strong> cluster-scale computation and scheduling</ul><p>The performance characteristics of each approach help guide selection:<h3 id=performance-trade-offs>Performance trade-offs</h3><ul><li><strong>In-process calls:</strong> microseconds → sub-milliseconds (depends on function)<li><strong>Local serialized IPC (ROS/DDS):</strong> sub-millisecond → multiple milliseconds per hop; depends on QoS, message size, and transport.<li><strong>Host↔device transfers:</strong> typically tens to hundreds of microseconds per transfer on PCIe; can be higher on lower-end buses. Batching can amortize cost.<li><strong>Memory:</strong> multiple processes duplicate runtime and loaded libraries; single process with threads/multiprocessing or ROS composition can save tens–hundreds of megabytes per service</ul><p>Actual numbers depend heavily on DDS vendor, QoS settings, transport (shared memory vs UDP), message size, and hardware. These ranges should be read as indicative, not guarantees.<p>Numbers are illustrative and vary by hardware and workload — profile for particular stacks.<h2 id=practical-patterns>Practical patterns</h2><p>These performance characteristics and tool capabilities suggest particular implementation patterns:<h3 id=communication-outside-computation-inside>Communication outside, computation inside</h3><p>Subsystems define communication boundaries; internal computation can use the most appropriate primitive.<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>ProcessingSystem</span>:
    <span style=color:#66d9ef>def</span> __init__(self):
        self<span style=color:#f92672>.</span>compute_core <span style=color:#f92672>=</span> ComputeCore()  <span style=color:#75715e># threads/processes/GPU</span>
        self<span style=color:#f92672>.</span>ros_interface <span style=color:#f92672>=</span> ROSInterface()  <span style=color:#75715e># marshal/unmarshal</span>

    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run</span>(self):
        <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>with</span> asyncio<span style=color:#f92672>.</span>TaskGroup() <span style=color:#66d9ef>as</span> tg:
            tg<span style=color:#f92672>.</span>create_task(self<span style=color:#f92672>.</span>compute_core<span style=color:#f92672>.</span>process())
            tg<span style=color:#f92672>.</span>create_task(self<span style=color:#f92672>.</span>ros_interface<span style=color:#f92672>.</span>publish())
</code></pre></div><h3 id=communication-nodes--architectural-boundaries>Communication nodes = architectural boundaries</h3><p>Grouping by responsibility rather than pipeline stages:<pre tabindex=0><code>/sensors     # drivers and raw aggregation
/processing  # heavy compute and inference
/planning    # decision-making
/control     # actuator commands and low-latency loops
</code></pre><p>Map internal concurrency to the problem inside each node:<ul><li>sensors: async streams / threads<li>processing: GPU + batching or multiprocessing<li>planning: single-process optimization (or Ray if distributed across machines)<li>control: low-latency threads or a dedicated real-time process</ul><p>This approach scales from single machines to larger deployments. For multi-machine or multi-robot systems, container orchestration becomes relevant at the system level.<h3 id=orchestration-boundaries>Orchestration boundaries</h3><p>Docker and Kubernetes manage containerized nodes, scheduling workloads across machines and enabling scaling or fault tolerance. These tools excel at system-level deployment concerns: distributing <code>/sensors</code>, <code>/processing</code>, <code>/planning</code>, and <code>/control</code> nodes across a fleet of robots or a compute cluster.<p>It’s worth noting that heavy orchestrators like Kubernetes are mostly used in cloud robotics or enterprise backends; embedded and real-time robots often can’t run them at all.<p>The anti-pattern emerges when orchestration tools are applied to fine-grained computation tasks that belong within a single process. Containerizing every step of a processing pipeline (where direct function calls or threads would suffice) introduces unnecessary serialization, network latency, and operational complexity.<p>The boundary principle applies here: use orchestration at system boundaries to manage node lifecycles and resource allocation, while internal computation leverages threads, async, multiprocessing, or GPU parallelism within those boundaries.<h3 id=context-matters>Context matters</h3><p>Different deployment contexts favor different strategies:<ul><li><strong>Edge devices</strong> <span style=color:#a9a9a9>(limited resources)</span> — Keep process counts low; ROS overhead is significant on embedded boards.<li><strong>Development environments</strong> <span style=color:#a9a9a9>(rapid iteration)</span> — More nodes may help with debugging and modularity; process isolation eases restarts.<li><strong>Mature deployments</strong> <span style=color:#a9a9a9>(production systems)</span> — Optimize for reliability, performance, and efficiency; consolidating over-distributed graphs.<li><strong>Real-time systems</strong> <span style=color:#a9a9a9>(deterministic timing)</span> — Favor direct calls and lightweight threading; avoiding (local) network hops in control loops.</ul><p>Note that sometimes the overhead of separate processes is intentional: isolating a flaky perception stack or ML model in its own process can prevent crashes from propagating to critical planners or controllers.
Furthermore, ROS 2 executors are not hard real-time safe; deterministic control loops are usually isolated in dedicated RT threads or processes outside the ROS executor.<h2 id=integration-considerations>Integration considerations</h2><p>When mixing communication and computation approaches, several implementation details become important:<ul><li><strong>ROS2 intra-process / composition:</strong> reduces serialization overhead but ties execution to ROS executors and lifecycle; most effective when nodes are colocated in a single process. Note that ROS 2 intra-process transport does not always achieve true zero-copy; behavior depends on message mutability and middleware support.<li><strong>rclpy and the GIL:</strong> <code>MultiThreadedExecutor</code> allows concurrent callbacks, but only one Python thread executes at a time; CPU-bound work is typically offloaded to processes, native extensions, or GPU kernels. These limitations are specific to rclpy; C++ nodes avoid the GIL but still face the same broader architectural trade-offs between threads, processes, and IPC.<li><strong>Mixing models (asyncio ↔ threads ↔ processes ↔ ROS):</strong> feasible but increases complexity; boundaries benefit from explicit documentation.<li><strong>ROS in a background thread with asyncio:</strong> <code>rclpy.spin</code> can run in a thread with callbacks forwarded to the asyncio loop via <code>asyncio.run_coroutine_threadsafe</code>.<li><strong>Blocking calls in asyncio:</strong> handled by wrapping calls with <code>await loop.run_in_executor(None, blocking_ros_call, args)</code> to maintain responsiveness.<li><strong>MultiThreadedExecutor:</strong> prevents long-running callbacks from stalling others.<li><strong>Bulk data transfer:</strong> shared memory or zero-copy DDS reduces overhead for large images, point clouds, or tensors.<li><strong>ROS at system boundaries:</strong> keeps core compute ROS-agnostic, isolating framework dependencies at the edges.</ul><h2 id=migration-considerations>Migration considerations</h2><p>When refactoring existing distributed systems, the objective is to reduce unnecessary communication overhead while preserving system boundaries that serve architectural purposes:<ul><li>Profile latency, copies, memory per process, and host↔device traffic<li>Identify high-state nodes and consider merging nodes sharing large mutable state or frequent large payloads<li>Preserve external APIs (topics/services) where clients rely on them<li>Verify timing-sensitive control loops after consolidation<li>Consider composition/intra-process transport or a single process with clear concurrency primitives and documented boundaries</ul><p>The overarching goal: use communication at boundaries and select computation primitives appropriate to in-process workloads.</div><footer class=post-footer><div class=post-meta>2025-09-27 · Opinions do not reflect those of affiliates.</div></footer></article></main></div><script type=module>
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

    
    document.addEventListener('DOMContentLoaded', () => {
      document.querySelectorAll('pre code.language-mermaid').forEach((block) => {
        const pre = block.parentElement;
        const mermaidDiv = document.createElement('div');
        mermaidDiv.className = 'mermaid';
        mermaidDiv.textContent = block.textContent;
        pre.replaceWith(mermaidDiv);
      });

      mermaid.initialize({
        startOnLoad: true,
        theme: 'base',
        themeVariables: {
          primaryColor: '#1a1a1a',
          primaryTextColor: '#e6e6e6',
          primaryBorderColor: '#86efac',
          lineColor: '#707070',
          secondaryColor: '#242424',
          tertiaryColor: '#0d0d0d',
          background: '#1a1a1a',
          mainBkg: '#1a1a1a',
          secondBkg: '#242424',
          textColor: '#e6e6e6',
          fontSize: '14px',
          fontFamily: 'Source Code Pro, monospace',
          edgeLabelBackground: '#1a1a1a'
        },
        flowchart: {
          useMaxWidth: true,
          htmlLabels: true,
          curve: 'linear',
          padding: 10,
          nodeSpacing: 30,
          rankSpacing: 40
        }
      });
    });
  </script>