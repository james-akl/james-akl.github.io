<!doctype html><html lang=en><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Distribution anti-patterns ~ James Akl</title><link rel=canonical href=https://jamesakl.com/posts/distribution-antipatterns/><link rel=icon href=/favicon.ico sizes=any><link rel=icon href=/favicon.svg type=image/svg+xml><meta name=description content="Two common distribution problems emerge in robotics systems: distributing computation and distributing communication.
ROS 2 (robotics middleware built on DDS …"><meta name=author content="James Akl"><meta property="og:type" content="article"><meta property="og:url" content="https://jamesakl.com/posts/distribution-antipatterns/"><meta property="og:title" content="Distribution anti-patterns ~ James Akl"><meta property="og:description" content="Two common distribution problems emerge in robotics systems: distributing computation and distributing communication.
ROS 2 (robotics middleware built on DDS …"><meta property="og:site_name" content="James Akl"><meta property="article:published_time" content="2025-09-27T00:00:00Z"><meta property="article:modified_time" content="2025-09-27T00:00:00Z"><meta property="article:author" content="James Akl"><meta name=twitter:card content="summary_large_image"><meta name=twitter:url content="https://jamesakl.com/posts/distribution-antipatterns/"><meta name=twitter:title content="Distribution anti-patterns ~ James Akl"><meta name=twitter:description content="Two common distribution problems emerge in robotics systems: distributing computation and distributing communication.
ROS 2 (robotics middleware built on DDS …"><meta name=twitter:creator content="@james_akl"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","name":"Distribution anti-patterns","headline":"Distribution anti-patterns","description":"Two common distribution problems emerge in robotics systems: distributing computation and distributing communication.\nROS 2 (robotics middleware built on DDS …","url":"https:\/\/jamesakl.com\/posts\/distribution-antipatterns\/","datePublished":"2025-09-27T00:00:00Z","dateModified":"2025-09-27T00:00:00Z","author":{"@type":"Person","name":"James Akl","url":"https:\/\/jamesakl.com"},"publisher":{"@type":"Person","name":"James Akl","url":"https:\/\/jamesakl.com"},"mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/jamesakl.com\/posts\/distribution-antipatterns\/"}}</script><link rel=alternate type=application/rss+xml title="James Akl" href=https://jamesakl.com/index.xml><link rel=sitemap type=application/xml title=Sitemap href=https://jamesakl.com/sitemap.xml><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@100;300&family=JetBrains+Mono:wght@100&display=swap" rel=stylesheet><style>:root{--primary-font:'JetBrains Mono', sans-serif;--secondary-font:'JetBrains Mono', monospace}[style*="var(--secondary-font)"],.mono{font-feature-settings:"kern" 1,"liga" 0,"calt" 0;letter-spacing:-.02em}body{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}@media(-webkit-min-device-pixel-ratio:2),(min-resolution:192dpi){body{-webkit-font-smoothing:antialiased}}</style><style>:root{--bg-primary:#0b0b0b;--bg-secondary:#1a1a1a;--text-primary:#f0f0f0;--text-secondary:#b0b0b0;--text-muted:#707070;--accent-primary:#66b3ff;--accent-secondary:#7ac373;--accent-warning:#ffb74d;--border-subtle:#2d2d2d;--border-focus:#404040}body{font:1rem/1.5 var(--primary-font);text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;font-feature-settings:"kern" 1,"liga" 1,"calt" 1;font-variant-ligatures:common-ligatures;padding:0;margin:0;background:var(--bg-primary);color:var(--text-primary);min-height:100vh;overflow-x:hidden;overflow-y:scroll}.site-container{max-width:76ch;margin:0 auto;padding:1.5rem;min-height:100vh;display:flex;flex-direction:column;box-sizing:border-box}.content{flex:1}h1,h2,h3,h4,h5,h6{line-height:1.3;margin:1.5rem 0 .75rem;font-weight:500}h1{font-size:2rem;margin-top:0;color:var(--text-primary)}h2{font-size:1.6rem;color:var(--text-primary)}h3{font-size:1.3rem}h4{font-size:1.1rem}p{margin:1rem 0;color:var(--text-primary)}strong{color:var(--accent-secondary);font-weight:500}a{color:var(--accent-primary);text-decoration:none;transition:all .2s ease;border-radius:2px}a:hover{color:var(--accent-secondary)}a:focus{outline:2px solid var(--accent-primary);outline-offset:2px}.site-header{display:flex;justify-content:space-between;align-items:center;padding:1rem 0 1.5rem;border-bottom:1px solid var(--border-subtle);margin-bottom:1.5rem}.site-title{font-family:var(--secondary-font);font-size:1.3rem;font-weight:400;color:var(--text-primary);text-decoration:none}.site-title:hover{color:var(--accent-primary)}.site-nav{display:flex;gap:1rem;align-items:center}.nav-icon{opacity:.7;transition:all .2s ease}.nav-icon:hover{opacity:1;transform:translateY(-1px)}.nav-icon svg{fill:#7ac373;transition:fill .2s ease}.nav-icon:hover svg{fill:#8fdd8f}.content-section{margin:1.5rem 0}.intro-text{font-size:1.1rem;line-height:1.55;color:var(--text-secondary);margin:1.5rem 0}hr{border:none;height:1px;background:linear-gradient(to right,transparent,var(--border-subtle),transparent);margin:2rem 0}strong{color:var(--accent-secondary);font-weight:500}.post-list{margin:1.5rem 0;font-family:var(--secondary-font)}.post-line{display:flex;justify-content:space-between;align-items:center;padding:.25rem 0;line-height:1.4}.post-line:hover{background-color:rgba(255,255,255,5%);margin:0 -.5rem;padding-left:.5rem;padding-right:.5rem}.post-link{color:var(--text-primary);text-decoration:none;flex:1;margin-right:1rem}.post-link:hover{color:var(--accent-primary)}.post-date{color:var(--text-muted);font-size:.9rem;white-space:nowrap}.post-excerpt{margin:.75rem 0 0;color:var(--text-secondary);line-height:1.5}.read-more{color:var(--accent-primary);font-size:.85rem;margin-top:.5rem;display:inline-block;line-height:1.5;font-weight:400}.read-more:hover{color:var(--accent-secondary)}.post-header{margin-bottom:1.5rem}.post-navigation{display:flex;justify-content:space-between;margin:2rem 0 1rem;padding:1rem 0;border-top:1px solid var(--border-subtle);font-size:.95rem}.post-nav-prev,.post-nav-next{flex:1}.post-nav-next{text-align:right}.post-nav-label{color:var(--text-muted);font-size:.85rem;display:block;margin-bottom:.25rem}.post-nav-title{color:var(--accent-primary);font-weight:500}.post-footer{margin-top:auto;margin-bottom:1rem;padding-top:1rem;border-top:1px solid var(--border-subtle);font-size:.8rem;color:var(--text-muted);line-height:1.4}.post-footer .post-meta{justify-content:center;text-align:center;margin:0;gap:.25rem}pre{background:var(--bg-secondary);border:1px solid var(--border-subtle);border-radius:6px;padding:1rem;margin:1rem 0;overflow-x:auto;font-family:var(--primary-font);font-size:.9rem;line-height:1.4;color:var(--text-primary)}code{font-family:var(--primary-font);font-size:.9em;background:var(--bg-secondary);color:var(--text-primary);padding:.2em .4em;margin:0 .15em;border-radius:3px;border:1px solid var(--border-subtle);word-wrap:break-word;overflow-wrap:break-word;white-space:pre-wrap;display:inline}pre code{background:0 0;border:none;padding:0;margin:0;font-size:inherit;color:inherit;white-space:pre;display:inline}@media(max-width:640px){.site-container{padding:1.5rem 1rem}.site-header{padding:1rem 0 1.25rem}h1{font-size:1.8rem}h2{font-size:1.5rem}.post-navigation{flex-direction:column;gap:1rem}.post-nav-next{text-align:left}.post-footer .post-meta{flex-direction:column;gap:.5rem;line-height:1.3}pre{padding:.75rem;font-size:.85rem}}</style><div class=site-container><header class=site-header><a class=site-title title=Home href=/>James Akl</a><nav class=site-nav><a class=nav-icon title=Resume href=/resume.pdf><svg width="1.2rem" height="1.2rem" viewBox="0 0 12 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M0 6H5c.55228.0 1-.44772 1-1V0H16c1.1046.0 2 .89543 2 2V22C18 23.1046 17.1046 24 16 24H2C.89543 24 0 23.1046.0 22V6zM.34141 4C.94398 2.29517 2.29517.943981 4 .341411V4H.34141zM5 11h8C13.5523 11 14 10.5523 14 10 14 9.44771 13.5523 9 13 9H5C4.44772 9 4 9.44771 4 10 4 10.5523 4.44772 11 5 11zm0 4h8C13.5523 15 14 14.5523 14 14S13.5523 13 13 13H5C4.44772 13 4 13.4477 4 14s.44772 1 1 1zm0 4h8C13.5523 19 14 18.5523 14 18S13.5523 17 13 17H5C4.44772 17 4 17.4477 4 18s.44772 1 1 1z"/></svg></a><a class=nav-icon title=LinkedIn href=https://www.linkedin.com/in/james-akl/><svg width="1.2rem" height="1.2rem" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M5.37214 24H.396429V7.97674H5.37214V24zM2.88161 5.79102C1.29054 5.79102.0 4.47317.0 2.8821.237147e-7 1.29063 1.29014 488281e-9 2.88161 488281e-9c1.59146.0 2.8816 1.290141719 2.8816 2.881611719.0 1.59107-1.29107 2.90892-2.8816 2.90892zM19.0296 24V16.2C19.0296 14.341 18.9921 11.9571 16.4427 11.9571c-2.587.0-2.9834 2.0196-2.9834 4.1089V24H8.48893V7.97674H13.2611V10.1625H13.3307C13.995 8.90352 15.6177 7.57495 18.0386 7.57495 23.0743 7.57495 24 10.891 24 15.1982V24H19.0296z"/></svg></a><a class=nav-icon title=Email href=mailto:james-akl@outlook.com><svg width="1.2rem" height="1.2rem" viewBox="0 0 24 12" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M23.4006 1.20046 13.1469 8.9765C12.4583 9.4585 11.5417 9.4585 10.8531 8.9765L.599433 1.20046C1.14673.47153 2.0183.0 3 0H21c.9817.0 1.8533.47153 2.4006 1.20046zM24 3.25413V15c0 1.6569-1.3431 3-3 3H3c-1.65685.0-3-1.3431-3-3V3.25413L9.70615 10.615c1.37725.9641 3.21045.9641 4.58765.0L24 3.25413z"/></svg></a><a class=nav-icon title="Google Scholar" href="https://scholar.google.com/citations?user=6gPp9TMAAAAJ"><svg width="1.3rem" height="1.3rem" viewBox="0 0 24 12" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M.522074 5.12131C.549569 5.10633.577846 5.09259.606828 5.08019L11.1724.27766c.5258-.23903 1.1294-.23903 1.6552.0l10.5862 4.8119C24.1954 5.44483 24.1954 6.555 23.4138 6.9103L12.8276 11.7222C12.3018 11.9612 11.6982 11.9612 11.1724 11.7222L2 7.5529v2.947c0 .552299999999999-.44772 1-1 1-.552285.0-1-.447700000000001-1-1V5.99993C0 5.98437 355195e-9 5.9689.00105792 5.95352.015847 5.6237.189526 5.3001.522074 5.12131zM20 10.462v2.262C20 13.0995 19.8943 13.4675 19.6949 13.7858 18.1427 16.2633 15.5333 17.4999 12 17.4999c-3.53329.0-6.14267-1.2366-7.69482-3.714C4.10583 13.4677 4.00009 13.0998 4 12.7241V10.462l7.1724 3.2602C11.6982 13.9612 12.3018 13.9612 12.8276 13.7222L20 10.462z"/></svg></a><a class=nav-icon title=Posts href=/posts><svg width="1.1rem" height="1.1rem" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 4H5c.55228.0 1 .44772 1 1V19C6 19.5523 5.55228 20 5 20H1C.44772 20 0 19.5523.0 19V5c0-.55228.44772-1 1-1zm1 9v4C2 17.5523 2.44772 18 3 18S4 17.5523 4 17V13C4 12.4477 3.55228 12 3 12S2 12.4477 2 13zM8 0h4C12.5523.0 13 .44772 13 1V19C13 19.5523 12.5523 20 12 20H8C7.44772 20 7 19.5523 7 19V1c0-.55228.44772-1 1-1zM9 11v6C9 17.5523 9.4477 18 10 18S11 17.5523 11 17V11C11 10.4477 10.5523 10 10 10S9 10.4477 9 11zm6-9h4C19.5523 2 20 2.44772 20 3V19C20 19.5523 19.5523 20 19 20H15C14.4477 20 14 19.5523 14 19V3C14 2.44772 14.4477 2 15 2zm1 13v2C16 17.5523 16.4477 18 17 18S18 17.5523 18 17V15C18 14.4477 17.5523 14 17 14S16 14.4477 16 15z"/></svg></a><a class=nav-icon title=GitHub href=https://github.com/james-akl><svg width="1.3rem" height="1.3rem" viewBox="0 0 24 23" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M12.2047 1e-5C6.56031-.005731 1.74628 4.08615.842541 9.6577-.061195 15.2293 3.2126 20.6331 8.56941 22.4118 9.14823 22.5177 9.35294 22.1577 9.35294 21.8541c0-.3035.0-.9953.0-1.9553C6.14117 20.5977 5.46353 18.3529 5.46353 18.3529 5.25046 17.6572 4.79779 17.0595 4.18588 16.6659 3.14823 15.96 4.27059 15.96 4.27059 15.96 5.00761 16.0641 5.65578 16.5014 6.02823 17.1459 6.34368 17.7179 6.87393 18.1406 7.50179 18.3208 8.12965 18.5009 8.8034 18.4236 9.37411 18.1059 9.41842 17.5252 9.66876 16.9794 10.08 16.5671 7.5247 16.2777 4.84235 15.2894 4.84235 10.92 4.82481 9.7786 5.24688 8.67412 6.02117 7.8353 5.67632 6.84285 5.71662 5.7571 6.13412 4.79295c0 0 .96705-.31059 3.16235 1.17882C11.1816 5.45419 13.1713 5.45419 15.0565 5.97177c2.1953-1.48941 3.1553-1.17882 3.1553-1.17882C18.6351 5.74689 18.6854 6.82486 18.3529 7.81412 19.1272 8.65294 19.5493 9.7574 19.5318 10.8988c0 4.4189-2.6894 5.3859-5.2518 5.6471C14.8359 17.1047 15.1218 17.8774 15.0635 18.6635c0 1.5389.0 2.7812.0 3.1553C15.0635 22.1929 15.2682 22.4824 15.8541 22.3694c5.2932-1.8247 8.5028-7.1966 7.6013-12.7225C22.5539 4.1211 17.8034.04779 12.2047 1e-5z"/></svg></a></nav></header><main class=content><article><header class=post-header><h1>Distribution anti-patterns</h1></header><div class=post-content><p>Two common distribution problems emerge in robotics systems: distributing <strong>computation</strong> and distributing <strong>communication</strong>.<p>ROS 2 <span style=color:#a9a9a9>(robotics middleware built on DDS for message passing and more)</span> is purpose-built for the communication problem — coordinating messages between robots, drivers, and software components across network boundaries. It is sometimes applied to the computation problem — parallelizing work inside a single system or process.<p>In prototyping, this approach can accelerate development. In more mature deployments, however, it can produce architectures where too many processing steps exist as separate nodes. This introduces serialization, network overhead, duplicated runtimes, and additional process management, where lighter concurrency primitives would suffice.<p>The core observation: <strong>the system&rsquo;s communication topology and the computation graph do not need to be identical.</strong> They can often be designed independently, reducing coupling to points where cross-process or cross-machine communication is genuinely required.<h2 id=the-two-problems>The two problems</h2><p>Understanding this anti-pattern requires distinguishing between two distinct distribution challenges:<p><strong>Distributed communication.</strong> Moving messages between processes, machines, or robots. ROS topics, services, and actions are designed for this; alternatives include ZeroMQ, RabbitMQ, Redis pub/sub, Kafka, or direct DDS for high-throughput or non-robotics applications.<p><strong>Distributed computation.</strong> Splitting work across cores, devices, or machines. This is handled by threading, multiprocessing, native accelerators (GPU, TPU, …), or distributed frameworks (Ray, Dask, Celery, …).<p>Note that “distributed” is usually reserved for work spread across multiple machines, while threads and processes on a single machine are described as parallelism or concurrency; here we discuss them together because the engineering trade-offs often overlap.<p>Most systems involve both: communication delivers results across boundaries, while computation accelerates processing within those boundaries. The issues can arise when tools designed for one problem are applied to the other.<h2 id=when-ros-becomes-the-default>When ROS becomes the default</h2><p>Faced with a parallel processing task, it is possible to implement each stage as a ROS node with appropriate communication primitives between them:<pre tabindex=0><code>/sensor_input → /preprocess → /algorithm → /post_process → /output
</code></pre><p>Costs of this pattern include:<ul><li>Serialization/deserialization and usually copies at each hop<li>Adaptation overhead and glue code for message types<li>Latency even for local operations (IPC ≠ direct call)<li>Duplicated memory/runtime across multiple processes, even when threads could suffice<li>Complexity in debugging and lifecycle management</ul><p>This illustrates using inter-system communication tools for intra-system computation. ROS 2 mitigations (composable nodes and intra-process transport) reduce per-hop overhead if nodes are colocated and the ROS execution model is followed, but this also admits the consideration of whether the processing work should be done via ROS.<h2 id=computation-tools>Computation tools</h2><p>Given this distinction, different tools address different aspects of the computation problem. Each offers specific trade-offs in concurrency, isolation, and performance:<h3 id=asyncio--cooperative-io>AsyncIO — cooperative I/O</h3><p>Useful for network or file I/O and coordinating multiple streams when callbacks are cooperative. Low scheduler overhead and avoids IPC when used within a single process. Less suitable for CPU-bound Python computation.<h3 id=threading--blocking-io-and-native-libraries>Threading — blocking I/O and native libraries</h3><p>Threads enable shared memory access while handling blocking I/O or delegating to native libraries that release the Python GIL. Practical for I/O-heavy tasks and interfacing with C/C++ extensions.<h3 id=multiprocessing--parallelism-and-isolation>Multiprocessing — parallelism and isolation</h3><p>Provides true parallelism for CPU-bound Python code. Offers process-level fault isolation and independent memory spaces.<h3 id=gpu-acceleration--high-throughput-local-compute-backend>GPU acceleration — high-throughput, local compute backend</h3><p>GPUs accelerate dense, data-parallel kernels such as matrix operations, convolutions, and large point-cloud filters. Practical considerations:<ul><li><strong>Batching and kernel aggregation:</strong> Minimize tiny host↔device transfers or kernel launches by combining operations or batching inputs.<li><strong>CUDA streams:</strong> Overlap computation and data transfer to improve device utilization. Input for batch <em>n+1</em> can transfer while batch <em>n</em> executes.<li><strong>Multi-GPU scaling:</strong> When a single GPU is insufficient, workloads can be partitioned across multiple GPUs (<em>e.g.</em>, <code>DistributedDataParallel</code> in <code>torch</code>), or across nodes using distributed frameworks like Ray.<li><strong>Shared memory / zero-copy:</strong> Large intermediate results exchanged with CPU processes or other GPUs benefit from shared memory (<code>multiprocessing.shared_memory</code>, CUDA pinned memory, or zero-copy DDS) to avoid repeated serialization.<li>The broader CUDA ecosystem also includes Unified Memory for simplifying host/device transfers, and NCCL for efficient multi-GPU communication.</ul><p>Illustrative pattern:<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>infer</span>(batch, device<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;cuda&#34;</span>):
    x <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(batch, device<span style=color:#f92672>=</span>device, copy<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
    <span style=color:#66d9ef>with</span> torch<span style=color:#f92672>.</span>no_grad():
        y <span style=color:#f92672>=</span> model(x)
    <span style=color:#66d9ef>return</span> y<span style=color:#f92672>.</span>cpu()<span style=color:#f92672>.</span>numpy()
</code></pre></div><p>Core points:<ul><li>Host↔device transfer latency and (de)serialization can dominate unless batching and stream concurrency are used.<li>Multi-GPU or distributed workloads require careful synchronization and memory management.<li>GPU computation often integrates with ROS or other frameworks at defined boundaries; maintaining computation in-process with clear interfaces simplifies coordination.</ul><h3 id=ray--dask--cluster-scale-computation>Ray / Dask — cluster-scale computation</h3><p>Used for multi-node scaling, distributed scheduling, and resilient execution. Appropriate when workloads exceed a single machine or require advanced scheduling/fault tolerance.<h3 id=ros--system-integration-and-cross-language-wiring>ROS — system integration and cross-language wiring</h3><p>ROS is most appropriate for hardware abstraction, driver stacks, multi-robot coordination, and interoperable message formats. Internal computation stages benefit from other concurrency primitives unless process isolation or robotics-specific tools are required.<h2 id=selection-criteria>Selection criteria</h2><p>These tools address different computational contexts:<ul><li><strong>ROS:</strong> integration surfaces, drivers, cross-process messaging<li><strong>AsyncIO:</strong> I/O-heavy pipelines inside a process<li><strong>Threading:</strong> blocking I/O or native libraries that release the GIL<li><strong>Multiprocessing:</strong> CPU-bound Python, isolation, multi-core scaling<li><strong>GPU:</strong> dense kernels, batched inference, heavy ops (minimize host↔device transfers)<li><strong>Ray/Dask:</strong> cluster-scale computation and scheduling</ul><p>The performance characteristics of each approach help guide selection:<h3 id=performance-trade-offs>Performance trade-offs</h3><ul><li><strong>In-process calls:</strong> microseconds → sub-milliseconds (depends on function)<li><strong>Local serialized IPC (ROS/DDS):</strong> sub-millisecond → multiple milliseconds per hop; depends on QoS, message size, and transport.<li><strong>Host↔device transfers:</strong> typically tens to hundreds of microseconds per transfer on PCIe; can be higher on lower-end buses. Batching can amortize cost.<li><strong>Memory:</strong> multiple processes duplicate runtime and loaded libraries; single process with threads/multiprocessing or ROS composition can save tens–hundreds of megabytes per service</ul><p>Actual numbers depend heavily on DDS vendor, QoS settings, transport (shared memory vs UDP), message size, and hardware. These ranges should be read as indicative, not guarantees.<p>Numbers are illustrative and vary by hardware and workload — profile for particular stacks.<h2 id=practical-patterns>Practical patterns</h2><p>These performance characteristics and tool capabilities suggest particular implementation patterns:<h3 id=communication-outside-computation-inside>Communication outside, computation inside</h3><p>Subsystems define communication boundaries; internal computation can use the most appropriate primitive.<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>ProcessingSystem</span>:
    <span style=color:#66d9ef>def</span> __init__(self):
        self<span style=color:#f92672>.</span>compute_core <span style=color:#f92672>=</span> ComputeCore()  <span style=color:#75715e># threads/processes/GPU</span>
        self<span style=color:#f92672>.</span>ros_interface <span style=color:#f92672>=</span> ROSInterface()  <span style=color:#75715e># marshal/unmarshal</span>

    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run</span>(self):
        <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>with</span> asyncio<span style=color:#f92672>.</span>TaskGroup() <span style=color:#66d9ef>as</span> tg:
            tg<span style=color:#f92672>.</span>create_task(self<span style=color:#f92672>.</span>compute_core<span style=color:#f92672>.</span>process())
            tg<span style=color:#f92672>.</span>create_task(self<span style=color:#f92672>.</span>ros_interface<span style=color:#f92672>.</span>publish())
</code></pre></div><h3 id=communication-nodes--architectural-boundaries>Communication nodes = architectural boundaries</h3><p>Grouping by responsibility rather than pipeline stages:<pre tabindex=0><code>/sensors     # drivers and raw aggregation
/processing  # heavy compute and inference
/planning    # decision-making
/control     # actuator commands and low-latency loops
</code></pre><p>Map internal concurrency to the problem inside each node:<ul><li>sensors: async streams / threads<li>processing: GPU + batching or multiprocessing<li>planning: single-process optimization (or Ray if distributed across machines)<li>control: low-latency threads or a dedicated real-time process</ul><p>This approach scales from single machines to larger deployments. For multi-machine or multi-robot systems, container orchestration becomes relevant at the system level.<h3 id=orchestration-boundaries>Orchestration boundaries</h3><p>Docker and Kubernetes manage containerized nodes, scheduling workloads across machines and enabling scaling or fault tolerance. These tools excel at system-level deployment concerns: distributing <code>/sensors</code>, <code>/processing</code>, <code>/planning</code>, and <code>/control</code> nodes across a fleet of robots or a compute cluster.<p>It’s worth noting that heavy orchestrators like Kubernetes are mostly used in cloud robotics or enterprise backends; embedded and real-time robots often can’t run them at all.<p>The anti-pattern emerges when orchestration tools are applied to fine-grained computation tasks that belong within a single process. Containerizing every step of a processing pipeline (where direct function calls or threads would suffice) introduces unnecessary serialization, network latency, and operational complexity.<p>The boundary principle applies here: use orchestration at system boundaries to manage node lifecycles and resource allocation, while internal computation leverages threads, async, multiprocessing, or GPU parallelism within those boundaries.<h3 id=context-matters>Context matters</h3><p>Different deployment contexts favor different strategies:<ul><li><strong>Edge devices</strong> <span style=color:#a9a9a9>(limited resources)</span> — Keep process counts low; ROS overhead is significant on embedded boards.<li><strong>Development environments</strong> <span style=color:#a9a9a9>(rapid iteration)</span> — More nodes may help with debugging and modularity; process isolation eases restarts.<li><strong>Mature deployments</strong> <span style=color:#a9a9a9>(production systems)</span> — Optimize for reliability, performance, and efficiency; consolidating over-distributed graphs.<li><strong>Real-time systems</strong> <span style=color:#a9a9a9>(deterministic timing)</span> — Favor direct calls and lightweight threading; avoiding (local) network hops in control loops.</ul><p>Note that sometimes the overhead of separate processes is intentional: isolating a flaky perception stack or ML model in its own process can prevent crashes from propagating to critical planners or controllers.
Furthermore, ROS 2 executors are not hard real-time safe; deterministic control loops are usually isolated in dedicated RT threads or processes outside the ROS executor.<h2 id=integration-considerations>Integration considerations</h2><p>When mixing communication and computation approaches, several implementation details become important:<ul><li><strong>ROS2 intra-process / composition:</strong> reduces serialization overhead but ties execution to ROS executors and lifecycle; most effective when nodes are colocated in a single process. Note that ROS 2 intra-process transport does not always achieve true zero-copy; behavior depends on message mutability and middleware support.<li><strong>rclpy and the GIL:</strong> <code>MultiThreadedExecutor</code> allows concurrent callbacks, but only one Python thread executes at a time; CPU-bound work is typically offloaded to processes, native extensions, or GPU kernels. These limitations are specific to rclpy; C++ nodes avoid the GIL but still face the same broader architectural trade-offs between threads, processes, and IPC.<li><strong>Mixing models (asyncio ↔ threads ↔ processes ↔ ROS):</strong> feasible but increases complexity; boundaries benefit from explicit documentation.<li><strong>ROS in a background thread with asyncio:</strong> <code>rclpy.spin</code> can run in a thread with callbacks forwarded to the asyncio loop via <code>asyncio.run_coroutine_threadsafe</code>.<li><strong>Blocking calls in asyncio:</strong> handled by wrapping calls with <code>await loop.run_in_executor(None, blocking_ros_call, args)</code> to maintain responsiveness.<li><strong>MultiThreadedExecutor:</strong> prevents long-running callbacks from stalling others.<li><strong>Bulk data transfer:</strong> shared memory or zero-copy DDS reduces overhead for large images, point clouds, or tensors.<li><strong>ROS at system boundaries:</strong> keeps core compute ROS-agnostic, isolating framework dependencies at the edges.</ul><h2 id=migration-considerations>Migration considerations</h2><p>When refactoring existing distributed systems, the objective is to reduce unnecessary communication overhead while preserving system boundaries that serve architectural purposes:<ul><li>Profile latency, copies, memory per process, and host↔device traffic<li>Identify high-state nodes and consider merging nodes sharing large mutable state or frequent large payloads<li>Preserve external APIs (topics/services) where clients rely on them<li>Verify timing-sensitive control loops after consolidation<li>Consider composition/intra-process transport or a single process with clear concurrency primitives and documented boundaries</ul><p>The overarching goal: use communication at boundaries and select computation primitives appropriate to in-process workloads.</div><footer class=post-footer><div class=post-meta>Published 2025-09-27 · Opinions are mine and do not reflect the views of affiliates.</div></footer></article></main></div><script src=/js/keynav.js></script>